{"id":"b1bb9a1f-c94f-4993-bbde-5f6fdd4ce422","revision":0,"last_node_id":23,"last_link_id":27,"nodes":[{"id":14,"type":"Note","pos":[160,570],"size":[260,90],"flags":{},"order":0,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["min_padding 1 is supposed to be the official way to inference chroma but I think the results are better with min_padding 0"],"color":"#432","bgcolor":"#653"},{"id":8,"type":"VAEDecode","pos":[770,610],"size":[140,46],"flags":{"collapsed":true},"order":12,"mode":0,"inputs":[{"localized_name":"samples","name":"samples","type":"LATENT","link":7},{"localized_name":"vae","name":"vae","type":"VAE","link":17}],"outputs":[{"localized_name":"IMAGE","name":"IMAGE","type":"IMAGE","slot_index":0,"links":[9]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"VAEDecode"},"widgets_values":[]},{"id":15,"type":"VAELoader","pos":[-220,410],"size":[350,60],"flags":{},"order":1,"mode":0,"inputs":[{"localized_name":"vae_name","name":"vae_name","type":"COMBO","widget":{"name":"vae_name"},"link":null}],"outputs":[{"localized_name":"VAE","name":"VAE","type":"VAE","links":[17]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"VAELoader","models":[{"name":"ae.safetensors","url":"https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors","directory":"vae"}]},"widgets_values":["ae.safetensors"]},{"id":19,"type":"MarkdownNote","pos":[-700,70],"size":[450,440],"flags":{},"order":2,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["Chroma is still continuously updating their model. You can visit [here](https://huggingface.co/lodestones/Chroma/tree/main) to get the latest version for download. For other models, if you have used models related to Flux, then you probably don't need to download them again.\n\n## Diffusion model\n\n[Chroma1-HD.safetensors](http://hf.x-gpu.com/lodestones/Chroma1-HD/resolve/main/Chroma1-HD.safetensors)\n\n## Text encoder\n[t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)\n\n## VAE\n\n[ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors)\n\n\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€ ðŸ“‚ models/\nâ”‚   â”œâ”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚     â””â”€â”€ Chroma1-HD.safetensors\nâ”‚   â”œâ”€ ðŸ“‚ text_encoders/\nâ”‚   â”‚     â””â”€â”€ t5xxl_fp8_e4m3fn_scaled.safetensors \nâ”‚   â””â”€ ðŸ“‚ vae/\nâ”‚            â””â”€â”€  ae.safetensors\n```\n"],"color":"#432","bgcolor":"#653"},{"id":12,"type":"EmptySD3LatentImage","pos":[-220,580],"size":[350,106],"flags":{},"order":3,"mode":0,"inputs":[{"localized_name":"width","name":"width","type":"INT","widget":{"name":"width"},"link":null},{"localized_name":"height","name":"height","type":"INT","widget":{"name":"height"},"link":null},{"localized_name":"batch_size","name":"batch_size","type":"INT","widget":{"name":"batch_size"},"link":null}],"outputs":[{"localized_name":"LATENT","name":"LATENT","type":"LATENT","links":[15]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"EmptySD3LatentImage"},"widgets_values":[1024,1648,1]},{"id":17,"type":"Note","pos":[160,110],"size":[268.4952392578125,107.76524353027344],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["This FreSca node makes anime images look better, if you are generating realistic images I recommend disabling it (CTRL-B)"],"color":"#432","bgcolor":"#653"},{"id":13,"type":"UNETLoader","pos":[-221.24722290039062,114.00627899169922],"size":[350,82],"flags":{},"order":5,"mode":0,"inputs":[{"localized_name":"unet_name","name":"unet_name","type":"COMBO","widget":{"name":"unet_name"},"link":null},{"localized_name":"weight_dtype","name":"weight_dtype","type":"COMBO","widget":{"name":"weight_dtype"},"link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":[27]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"UNETLoader","models":[{"name":"Chroma1-HD.safetensors","url":"https://huggingface.co/lodestones/Chroma1-HD/resolve/main/Chroma1-HD.safetensors","directory":"diffusion_models"}]},"widgets_values":["Chroma1-HD.safetensors","default"]},{"id":9,"type":"SaveImage","pos":[950,70],"size":[490,860],"flags":{},"order":13,"mode":0,"inputs":[{"localized_name":"images","name":"images","type":"IMAGE","link":9},{"localized_name":"filename_prefix","name":"filename_prefix","type":"STRING","widget":{"name":"filename_prefix"},"link":null}],"outputs":[],"properties":{"cnr_id":"comfy-core","ver":"0.3.39"},"widgets_values":["Skugli"]},{"id":11,"type":"T5TokenizerOptions","pos":[160,430],"size":[270,82],"flags":{},"order":8,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":14},{"localized_name":"min_padding","name":"min_padding","type":"INT","widget":{"name":"min_padding"},"link":null},{"localized_name":"min_length","name":"min_length","type":"INT","widget":{"name":"min_length"},"link":null}],"outputs":[{"localized_name":"CLIP","name":"CLIP","type":"CLIP","links":[12,20]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"T5TokenizerOptions"},"widgets_values":[2,0]},{"id":10,"type":"CLIPLoader","pos":[-221.24722290039062,248.00628662109375],"size":[350,110],"flags":{},"order":6,"mode":0,"inputs":[{"localized_name":"clip_name","name":"clip_name","type":"COMBO","widget":{"name":"clip_name"},"link":null},{"localized_name":"type","name":"type","type":"COMBO","widget":{"name":"type"},"link":null},{"localized_name":"device","name":"device","shape":7,"type":"COMBO","widget":{"name":"device"},"link":null}],"outputs":[{"localized_name":"CLIP","name":"CLIP","type":"CLIP","links":[14]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"CLIPLoader","models":[{"name":"t5xxl_fp8_e4m3fn_scaled.safetensors","url":"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors","directory":"text_encoders"}]},"widgets_values":["t5xxl_fp8_e4m3fn_scaled.safetensors","chroma","default"]},{"id":3,"type":"KSampler","pos":[470,600],"size":[280,262],"flags":{},"order":11,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":27},{"localized_name":"positive","name":"positive","type":"CONDITIONING","link":4},{"localized_name":"negative","name":"negative","type":"CONDITIONING","link":6},{"localized_name":"latent_image","name":"latent_image","type":"LATENT","link":15},{"localized_name":"seed","name":"seed","type":"INT","widget":{"name":"seed"},"link":null},{"localized_name":"steps","name":"steps","type":"INT","widget":{"name":"steps"},"link":null},{"localized_name":"cfg","name":"cfg","type":"FLOAT","widget":{"name":"cfg"},"link":null},{"localized_name":"sampler_name","name":"sampler_name","type":"COMBO","widget":{"name":"sampler_name"},"link":null},{"localized_name":"scheduler","name":"scheduler","type":"COMBO","widget":{"name":"scheduler"},"link":null},{"localized_name":"denoise","name":"denoise","type":"FLOAT","widget":{"name":"denoise"},"link":null}],"outputs":[{"localized_name":"LATENT","name":"LATENT","type":"LATENT","slot_index":0,"links":[7]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"KSampler"},"widgets_values":[925779900109352,"randomize",40,6.5,"dpmpp_2m_sde","karras",0.8]},{"id":16,"type":"FreSca","pos":[160,270],"size":[270,110],"flags":{},"order":7,"mode":4,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null},{"localized_name":"scale_low","name":"scale_low","type":"FLOAT","widget":{"name":"scale_low"},"link":null},{"localized_name":"scale_high","name":"scale_high","type":"FLOAT","widget":{"name":"scale_high"},"link":null},{"localized_name":"freq_cutoff","name":"freq_cutoff","type":"INT","widget":{"name":"freq_cutoff"},"link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":[]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"FreSca"},"widgets_values":[1,2.5000000000000004,30]},{"id":6,"type":"CLIPTextEncode","pos":[480,140],"size":[422.84503173828125,164.31304931640625],"flags":{},"order":10,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":20},{"localized_name":"text","name":"text","type":"STRING","widget":{"name":"text"},"link":null}],"outputs":[{"localized_name":"CONDITIONING","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[4]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"CLIPTextEncode"},"widgets_values":["DwarfPosePrompt = \"In the foreground, a dwarven barbarian leaps into frame, axe raised behind his head in both hands. His knees are bent, legs tucked midair, body twisting upward with force. He wears aged copper armor with green verdigris patina and a full helmet. His red beard streams behind him.\"\n\nMonsterPosePrompt = \"Midair across from him, a massive four-armed albino gorilla-like beast (Girallon) leaps forward in rage. Its two main arms are raised to strike, while two smaller secondary arms hang from its lower torso, twisted and slack with green ooze. A long tail whips behind it.\"\n\nScenePrompt = \"The two figures are suspended above a broken stone road through a jungle clearing, with dappled sunlight filtering through the canopy. Vines, trees, and mossy stones frame the background.\"\n\nCompositionPrompt = \"The scene is viewed over the dwarf's shoulder, framing the monster in front of him. The moment is frozen just before impact. No blood or wounds â€” only cinematic tension and motion.\"\n\nVisualStylePrompt = \"A traditional-style fantasy illustration in a semi-realistic painterly aesthetic. Strong character silhouettes, bold lighting, and hand-painted texture detail reminiscent of storybook or concept art. Colors are rich but muted, using warm shadows and atmospheric depth. Linework is minimal or fully blended. The composition evokes dynamic movement and cinematic framing. Ideal for print or digital publication.\"\n\n# FullPrompt = DwarfPosePrompt + MonsterPosePrompt + ScenePrompt + CompositionPrompt + VisualStylePrompt"],"color":"#232","bgcolor":"#353"},{"id":7,"type":"CLIPTextEncode","pos":[480,360],"size":[420,140],"flags":{},"order":9,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":12},{"localized_name":"text","name":"text","type":"STRING","widget":{"name":"text"},"link":null}],"outputs":[{"localized_name":"CONDITIONING","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[6]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.39","Node name for S&R":"CLIPTextEncode"},"widgets_values":["# === Anatomy Suppression ===\nbad anatomy, missing limbs, extra limbs, fused arms, broken bones, malformed, poor proportions, unrealistic muscle, disconnected limbs, duplicate limbs\n\n# === Visual Clarity / Shape Errors ===\nblurry, soft focus, floating objects, indistinct shapes, occluded faces, bad perspective, low contrast, bad silhouette, messy composition\n\n# === Lighting & Glow Suppression ===\nambient glow, green glow, soft glow, glowing fog, radioactive haze, neon lighting, light bloom, overexposed lighting, bloom lighting, washed out\n\n# === Style Mismatches ===\ncomic style, 3d render, cg artifact, cheap texture, toy-like design, lowpoly, photobashing, sketch overlay, grayscale\n\n# === Content Violations ===\nblood, gore, injury, dismemberment, body horror, open wounds, exposed flesh, horror elements\n\n# === Artifact Suppression ===\nwatermark, signature, text artifact, frame border, glitch"],"color":"#323","bgcolor":"#535"}],"links":[[4,6,0,3,1,"CONDITIONING"],[6,7,0,3,2,"CONDITIONING"],[7,3,0,8,0,"LATENT"],[9,8,0,9,0,"IMAGE"],[12,11,0,7,0,"CLIP"],[14,10,0,11,0,"CLIP"],[15,12,0,3,3,"LATENT"],[17,15,0,8,1,"VAE"],[20,11,0,6,0,"CLIP"],[27,13,0,3,0,"MODEL"]],"groups":[{"id":1,"title":"Step 1: load models","bounding":[-230,40,370,460],"color":"#3f789e","font_size":24,"flags":{}},{"id":2,"title":"Step 2: image size","bounding":[-230,510,370,189.60000610351562],"color":"#3f789e","font_size":24,"flags":{}},{"id":3,"title":"Step 3: prompts","bounding":[460,40,460,480],"color":"#3f789e","font_size":24,"flags":{}},{"id":4,"title":"Optional","bounding":[150,40,290,660],"color":"#3f789e","font_size":24,"flags":{}},{"id":5,"title":"Sampling & Decoding","bounding":[460,530,460,340],"color":"#3f789e","font_size":24,"flags":{}}],"config":{},"extra":{"ds":{"scale":0.8784093960751276,"offset":[241.6386109856569,-46.30369265052126]},"frontendVersion":"1.25.9"},"version":0.4}